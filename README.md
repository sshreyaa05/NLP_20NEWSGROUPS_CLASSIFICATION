### 20 Newsgroups Text Classification Using Word2Vec and Average Word2Vec

### Short Description:
This project focuses on text classification of the 20 Newsgroups dataset using Word2Vec and Average Word2Vec embeddings. We performed text preprocessing, including tokenization and stemming, to clean the data. The Word2Vec model was then implemented to transform text tokens into numerical vectors. After that, we applied padding sequences to ensure uniform input lengths. A simple Artificial Neural Network (ANN) was used for classification, and the same process was repeated for Average Word2Vec embeddings. Upon evaluation, Average Word2Vec outperformed Word2Vec, achieving slightly higher accuracy in classifying newsgroup articles.

### Results:

a. Average Word2Vec achieved slightly higher accuracy, making it the better-performing model.

b. Word2Vec also performed well, but its accuracy was slightly lower than the Average Word2Vec model.

c. Text preprocessing (tokenization and stemming) improved model efficiency, while sequence padding ensured compatibility with the ANN model.






